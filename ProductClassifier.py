# -*- coding: utf-8 -*-
"""Modulo 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1az7UOXKoKhC4v2g3RfT52e1SB3-T7uZR
"""

!pip install torch-summary

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import kagglehub

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.utils import make_grid
from torchsummary import summary

from sklearn.metrics import confusion_matrix, classification_report
import plotly.express as px
from tqdm.notebook import tqdm

# Configuración de semillas para reproducibilidad
torch.manual_seed(42)
np.random.seed(42)

# Configuración de dispositivo
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 1. Carga y Preparación de Datos
class ProductImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['jeans', 'sofa', 'tshirt', 'tv']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

        self.image_paths = []
        self.labels = []

        # Recorrer todas las clases y recopilar rutas de imágenes
        for class_name in self.classes:
            class_dir = os.path.join(root_dir, class_name)
            for img_name in os.listdir(class_dir):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.image_paths.append(os.path.join(class_dir, img_name))
                    self.labels.append(self.class_to_idx[class_name])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# Definir transformaciones
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 2. Modelo CNN

class ProductClassifier(nn.Module):
    def __init__(self):
        super(ProductClassifier, self).__init__()

        # Dos bloques convolucionales simples
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)

        # Un solo batch normalization
        self.bn = nn.BatchNorm2d(64)

        # Pooling
        self.pool = nn.MaxPool2d(2, 2)

        # Una capa fully connected más pequeña
        self.fc1 = nn.Linear(64 * 56 * 56, 256)
        self.fc2 = nn.Linear(256, 4)  # 4 clases

        # Un solo dropout
        self.dropout = nn.Dropout(0.3)

    def forward(self, x):
        # Primer bloque convolucional
        x = self.pool(F.relu(self.conv1(x)))

        # Segundo bloque convolucional con batch norm
        x = self.pool(F.relu(self.bn(self.conv2(x))))

        # Aplanar
        x = x.view(-1, 64 * 56 * 56)

        # Fully connected con dropout
        x = self.dropout(F.relu(self.fc1(x)))
        x = self.fc2(x)

        return x

# 3. Callbacks y utilidades
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False

    def __call__(self, val_loss):
        if self.best_loss is None:
            self.best_loss = val_loss
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.counter = 0

# 4. Funciones de visualización
def plot_dataset_distribution(dataset):
    class_counts = {}
    for _, label in dataset:
        class_name = dataset.classes[label]
        class_counts[class_name] = class_counts.get(class_name, 0) + 1

    plt.figure(figsize=(10, 6))
    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))
    plt.title('Distribución de clases en el dataset')
    plt.xlabel('Clase')
    plt.ylabel('Número de imágenes')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def visualize_batch(dataloader, classes):
    images, labels = next(iter(dataloader))
    plt.figure(figsize=(15, 8))
    grid = make_grid(images[:16], nrow=4, normalize=True)
    plt.imshow(grid.permute(1, 2, 0))
    plt.title('Ejemplos de imágenes del dataset')
    plt.axis('off')

def plot_training_history(history):
    plt.figure(figsize=(12, 4))

    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Loss durante el entrenamiento')
    plt.xlabel('Época')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Train Accuracy')
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.title('Accuracy durante el entrenamiento')
    plt.xlabel('Época')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(y_true, y_pred, classes, figsize=(10, 8), title='Matriz de Confusión'):
    cm = confusion_matrix(y_true, y_pred)

    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.figure(figsize=figsize)

    sns.heatmap(cm,
                annot=True,
                fmt='.2%',
                cmap='Blues',
                xticklabels=classes,
                yticklabels=classes)

    plt.title(title)
    plt.ylabel('Etiqueta Real')
    plt.xlabel('Predicción')

    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)

    plt.tight_layout()

    plt.show()


def visualize_predictions(model, dataloader, classes, num_images=16):
    model.eval()
    images, labels = next(iter(dataloader))
    images = images[:num_images]
    labels = labels[:num_images]

    with torch.no_grad():
        outputs = model(images.to(device))
        _, preds = torch.max(outputs, 1)

    fig = plt.figure(figsize=(15, 10))
    rows = int(np.sqrt(num_images))
    cols = int(np.ceil(num_images / rows))

    mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)
    std = torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1)
    images = images * std + mean

    for idx in range(num_images):
        ax = fig.add_subplot(rows, cols, idx + 1, xticks=[], yticks=[])
        img = images[idx].permute(1, 2, 0).numpy()
        img = np.clip(img, 0, 1)

        plt.imshow(img)

        pred_class = classes[preds[idx].cpu()]
        true_class = classes[labels[idx]]
        color = 'green' if pred_class == true_class else 'red'

        title = f'Pred: {pred_class}\nReal: {true_class}'
        ax.set_title(title, color=color)

    plt.tight_layout()
    plt.show()

    correct = (preds.cpu() == labels).sum().item()
    print(f"\nEstadísticas de las {num_images} predicciones mostradas:")
    print(f"Correctas: {correct} ({100*correct/num_images:.1f}%)")
    print(f"Incorrectas: {num_images-correct} ({100*(num_images-correct)/num_images:.1f}%)")

# 5. Función de entrenamiento
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, early_stopping):
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    for epoch in range(num_epochs):
        # Entrenamiento
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0

        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()

        # Validación
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()

        # Calcular métricas
        train_loss = train_loss / len(train_loader)
        train_acc = 100. * train_correct / train_total
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * val_correct / val_total

        # Guardar historia
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        print(f'Epoch {epoch+1}/{num_epochs}:')
        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

        # Early Stopping
        early_stopping(val_loss)
        if early_stopping.early_stop:
            print("Early stopping triggered")
            break

    return history

# Cargar dataset
path = kagglehub.dataset_download("sunnykusawa/ecommerce-products-image-dataset")
ecommerce_products_path = os.path.join(path, "ecommerce products")

# Crear datasets
full_dataset = ProductImageDataset(ecommerce_products_path, transform=train_transform)

# Dividir en train y validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(
    full_dataset, [train_size, val_size]
)

# Crear dataloaders
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# Visualizar distribución del dataset
plot_dataset_distribution(full_dataset)

# Visualizar batch de ejemplo
visualize_batch(train_loader, full_dataset.classes)

# Crear modelo
model = ProductClassifier().to(device)

# Mostrar resumen del modelo
summary(model, (3, 224, 224))

# Configurar entrenamiento
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
early_stopping = EarlyStopping(patience=5)

# Entrenar modelo
history = train_model(
    model, train_loader, val_loader,
    criterion, optimizer, num_epochs=10,
    early_stopping=early_stopping
)

# Visualizar resultados del entrenamiento
plot_training_history(history)

# Evaluar modelo
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in val_loader:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = outputs.max(1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Mostrar matriz de confusión
plot_confusion_matrix(all_labels, all_preds, full_dataset.classes)

# Mostrar reporte de clasificación
print("\nReporte de Clasificación:")
print(classification_report(all_labels, all_preds,
                          target_names=full_dataset.classes))

# Ejemplo de uso
visualize_predictions(model, val_loader, full_dataset.classes)

def save_model_pickle(model, path='model.pkl'):
    import pickle
    with open(path, 'wb') as f:
        pickle.dump(model, f)
    print(f"Modelo guardado en: {path}")

def load_model_pickle(path='model.pkl'):
    import pickle
    with open(path, 'rb') as f:
        model = pickle.load(f)
    model.eval()
    return model

save_model_pickle(model, 'ecommerce_classifier.pkl')

model = load_model_pickle('ecommerce_classifier.pkl')

import torch

# Suponiendo que ya tienes el modelo entrenado
torch.save(model.state_dict(), "ecommerce_classifier.pth")
print("Modelo guardado en ecommerce_classifier.pth")
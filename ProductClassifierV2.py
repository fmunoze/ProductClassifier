# -*- coding: utf-8 -*-
"""Modulo 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1az7UOXKoKhC4v2g3RfT52e1SB3-T7uZR

https://appuctclassifier-nns8ekvzblgq2gkh3rwxud.streamlit.app/
"""

!pip install torch-summary

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import kagglehub

import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from torchvision.utils import make_grid
from torchsummary import summary

from sklearn.metrics import confusion_matrix, classification_report
import plotly.express as px
from tqdm.notebook import tqdm

# Configuración de semillas para reproducibilidad
torch.manual_seed(42)
np.random.seed(42)

# Configuración de dispositivo
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# 1. Carga y Preparación de Datos
class ProductImageDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['jeans', 'sofa', 'tshirt', 'tv']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}

        self.image_paths = []
        self.labels = []

        # Recorrer todas las clases y recopilar rutas de imágenes
        for class_name in self.classes:
            class_dir = os.path.join(root_dir, class_name)
            for img_name in os.listdir(class_dir):
                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    self.image_paths.append(os.path.join(class_dir, img_name))
                    self.labels.append(self.class_to_idx[class_name])

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        image = Image.open(img_path).convert('RGB')
        label = self.labels[idx]

        if self.transform:
            image = self.transform(image)

        return image, label

# Definir transformaciones - Mejoradas para ResNet
train_transform = transforms.Compose([
    transforms.Resize((256, 256)),  # Redimensionamiento más grande
    transforms.RandomCrop(224),     # Recorte aleatorio para aumentar la diversidad
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

val_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# 2. Modelo ResNet
class ResNetProductClassifier(nn.Module):
    def __init__(self, num_classes=4):
        super(ResNetProductClassifier, self).__init__()
        # Cargar ResNet18 preentrenado
        self.resnet = models.resnet50(pretrained=True)

        # Congelar las primeras capas para evitar overfitting
        for param in list(self.resnet.parameters())[:-30]:  # Mantener fijas las primeras capas
            param.requires_grad = False

        # Modificar la capa final para nuestro problema de clasificación
        num_features = self.resnet.fc.in_features
        self.resnet.fc = nn.Sequential(
            nn.Linear(num_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        return self.resnet(x)

# 3. Callbacks y utilidades
class EarlyStopping:
    def __init__(self, patience=7, min_delta=0, verbose=True):
        self.patience = patience
        self.min_delta = min_delta
        self.counter = 0
        self.best_loss = None
        self.early_stop = False
        self.verbose = verbose
        self.best_model_state = None

    def __call__(self, val_loss, model):
        if self.best_loss is None:
            self.best_loss = val_loss
            self.best_model_state = model.state_dict().copy()
        elif val_loss > self.best_loss - self.min_delta:
            self.counter += 1
            if self.verbose:
                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')
            if self.counter >= self.patience:
                self.early_stop = True
        else:
            self.best_loss = val_loss
            self.best_model_state = model.state_dict().copy()
            self.counter = 0

    def restore_best_model(self, model):
        if self.best_model_state is not None:
            model.load_state_dict(self.best_model_state)
            if self.verbose:
                print('Restored model to best weights')
        return model

# 4. Funciones de visualización
def plot_dataset_distribution(dataset):
    class_counts = {}
    for _, label in dataset:
        class_name = dataset.classes[label]
        class_counts[class_name] = class_counts.get(class_name, 0) + 1

    plt.figure(figsize=(10, 6))
    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))
    plt.title('Distribución de clases en el dataset')
    plt.xlabel('Clase')
    plt.ylabel('Número de imágenes')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

def visualize_batch(dataloader, classes):
    images, labels = next(iter(dataloader))
    plt.figure(figsize=(15, 8))
    grid = make_grid(images[:16], nrow=4, normalize=True)
    plt.imshow(grid.permute(1, 2, 0))
    plt.title('Ejemplos de imágenes del dataset')
    plt.axis('off')
    plt.show()

    # Mostrar etiquetas
    label_names = [classes[lbl] for lbl in labels[:16]]
    for i, name in enumerate(label_names):
        print(f"Imagen {i+1}: {name}")

def plot_training_history(history):
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='Train Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Loss durante el entrenamiento')
    plt.xlabel('Época')
    plt.ylabel('Loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='Train Accuracy')
    plt.plot(history['val_acc'], label='Validation Accuracy')
    plt.title('Accuracy durante el entrenamiento')
    plt.xlabel('Época')
    plt.ylabel('Accuracy (%)')
    plt.legend()

    plt.tight_layout()
    plt.show()

def plot_confusion_matrix(y_true, y_pred, classes, figsize=(10, 8), title='Matriz de Confusión'):
    cm = confusion_matrix(y_true, y_pred)

    # Normalizar matriz para porcentajes
    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]

    plt.figure(figsize=figsize)

    # Matriz original (recuentos)
    plt.subplot(1, 2, 1)
    sns.heatmap(cm,
                annot=True,
                fmt='d',
                cmap='Blues',
                xticklabels=classes,
                yticklabels=classes)
    plt.title(f"{title} (recuentos)")
    plt.ylabel('Etiqueta Real')
    plt.xlabel('Predicción')
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)

    # Matriz normalizada (porcentajes)
    plt.subplot(1, 2, 2)
    sns.heatmap(cm_normalized,
                annot=True,
                fmt='.1%',
                cmap='Blues',
                xticklabels=classes,
                yticklabels=classes)
    plt.title(f"{title} (porcentajes)")
    plt.ylabel('Etiqueta Real')
    plt.xlabel('Predicción')
    plt.xticks(rotation=45, ha='right')
    plt.yticks(rotation=0)

    plt.tight_layout()
    plt.show()

def visualize_predictions(model, dataloader, classes, num_images=16):
    model.eval()
    images, labels = next(iter(dataloader))
    images = images[:num_images]
    labels = labels[:num_images]

    with torch.no_grad():
        outputs = model(images.to(device))
        _, preds = torch.max(outputs, 1)

    fig = plt.figure(figsize=(15, 10))
    rows = int(np.sqrt(num_images))
    cols = int(np.ceil(num_images / rows))

    mean = torch.tensor([0.485, 0.456, 0.406]).reshape(3,1,1)
    std = torch.tensor([0.229, 0.224, 0.225]).reshape(3,1,1)
    images = images * std + mean  # desnormalizar

    for idx in range(num_images):
        ax = fig.add_subplot(rows, cols, idx + 1, xticks=[], yticks=[])
        img = images[idx].permute(1, 2, 0).numpy()
        img = np.clip(img, 0, 1)  # Asegurar que los valores estén entre 0 y 1

        plt.imshow(img)

        pred_class = classes[preds[idx].cpu()]
        true_class = classes[labels[idx]]
        color = 'green' if pred_class == true_class else 'red'

        title = f'Pred: {pred_class}\nReal: {true_class}'
        ax.set_title(title, color=color)

    plt.tight_layout()
    plt.show()

    correct = (preds.cpu() == labels).sum().item()
    print(f"\nEstadísticas de las {num_images} predicciones mostradas:")
    print(f"Correctas: {correct} ({100*correct/num_images:.1f}%)")
    print(f"Incorrectas: {num_images-correct} ({100*(num_images-correct)/num_images:.1f}%)")

# 5. Función de entrenamiento con cosine annealing scheduler
def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, early_stopping):
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    for epoch in range(num_epochs):
        # Entrenamiento
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0

        for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):
            images, labels = images.to(device), labels.to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)

            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += labels.size(0)
            train_correct += predicted.eq(labels).sum().item()

        # Actualizar el learning rate scheduler
        if scheduler is not None:
            scheduler.step()
            current_lr = optimizer.param_groups[0]['lr']
            print(f"Current learning rate: {current_lr:.6f}")

        # Validación
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for images, labels in val_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                loss = criterion(outputs, labels)

                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += labels.size(0)
                val_correct += predicted.eq(labels).sum().item()

        # Calcular métricas
        train_loss = train_loss / len(train_loader)
        train_acc = 100. * train_correct / train_total
        val_loss = val_loss / len(val_loader)
        val_acc = 100. * val_correct / val_total

        # Guardar historia
        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        print(f'Epoch {epoch+1}/{num_epochs}:')
        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

        # Early Stopping
        early_stopping(val_loss, model)
        if early_stopping.early_stop:
            print("Early stopping triggered")
            break

    # Restaurar el mejor modelo
    model = early_stopping.restore_best_model(model)
    return history, model

# Función para guardar y cargar modelo
def save_model(model, path='model.pth'):
    torch.save({
        'model_state_dict': model.state_dict(),
        'class_names': full_dataset.classes
    }, path)
    print(f"Modelo guardado en: {path}")

def load_model(path='model.pth', num_classes=4):
    checkpoint = torch.load(path, map_location=device)
    model = ResNetProductClassifier(num_classes=num_classes).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    return model, checkpoint['class_names']

# ================================ EJECUCIÓN PRINCIPAL ================================
print("Iniciando carga del dataset...")

# Cargar dataset
path = kagglehub.dataset_download("sunnykusawa/ecommerce-products-image-dataset")
ecommerce_products_path = os.path.join(path, "ecommerce products")

# Crear datasets
full_dataset = ProductImageDataset(ecommerce_products_path, transform=train_transform)

# Dividir en train y validation
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(
    full_dataset, [train_size, val_size]
)

# Aplicar transformaciones específicas para cada conjunto
train_dataset.dataset.transform = train_transform
val_dataset.dataset.transform = val_transform

# Crear dataloaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4, pin_memory=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4, pin_memory=True)

print(f"Dataset cargado. Total de imágenes: {len(full_dataset)}")
print(f"Imágenes de entrenamiento: {len(train_dataset)}")
print(f"Imágenes de validación: {len(val_dataset)}")

# Visualizar distribución del dataset
plot_dataset_distribution(full_dataset)

# Visualizar batch de ejemplo
visualize_batch(train_loader, full_dataset.classes)

# Crear modelo ResNet
model = ResNetProductClassifier(num_classes=len(full_dataset.classes)).to(device)

# Mostrar resumen del modelo
summary(model, (3, 224, 224))

# Configurar entrenamiento
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam([
    {'params': list(model.resnet.fc.parameters()), 'lr': 1e-3},  # Capa personalizada: mayor learning rate
    {'params': [p for n, p in model.named_parameters() if 'fc' not in n and p.requires_grad], 'lr': 1e-4}  # Capas preentrenadas: menor learning rate
])

# Scheduler para reducir el learning rate
scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-6)

# Early stopping mejorado
early_stopping = EarlyStopping(patience=5, verbose=True)

# Entrenar modelo
print("Iniciando entrenamiento...")
history, model = train_model(
    model, train_loader, val_loader,
    criterion, optimizer, scheduler, num_epochs=25,
    early_stopping=early_stopping
)

# Visualizar resultados del entrenamiento
plot_training_history(history)

# Evaluar modelo
model.eval()
all_preds = []
all_labels = []

with torch.no_grad():
    for images, labels in tqdm(val_loader, desc="Evaluando modelo"):
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        _, predicted = outputs.max(1)
        all_preds.extend(predicted.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Mostrar matriz de confusión
plot_confusion_matrix(all_labels, all_preds, full_dataset.classes)

# Mostrar reporte de clasificación
print("\nReporte de Clasificación:")
print(classification_report(all_labels, all_preds,
                          target_names=full_dataset.classes))

# Ejemplos de uso
visualize_predictions(model, val_loader, full_dataset.classes, num_images=16)

# Guardar modelo
save_model(model, 'resnet_ecommerce_classifier.pth')
print("¡Entrenamiento completo!")

# Función para realizar una predicción sobre una nueva imagen
def predict_image(model, image_path, classes):
    # Cargar y transformar la imagen
    image = Image.open(image_path).convert('RGB')
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])

    # Preparar la imagen para el modelo
    image_tensor = transform(image).unsqueeze(0).to(device)

    # Hacer la predicción
    model.eval()
    with torch.no_grad():
        output = model(image_tensor)
        _, predicted = torch.max(output, 1)
        confidence = F.softmax(output, dim=1)

    # Obtener la clase y la confianza
    predicted_class = classes[predicted.item()]
    prediction_confidence = confidence[0][predicted.item()].item() * 100

    # Mostrar la imagen con la predicción
    plt.figure(figsize=(6, 6))
    plt.imshow(image)
    plt.title(f'Predicción: {predicted_class}\nConfianza: {prediction_confidence:.2f}%')
    plt.axis('off')
    plt.show()

    # Mostrar confianza para todas las clases
    print("Confianza por clase:")
    for i, cls in enumerate(classes):
        print(f"{cls}: {confidence[0][i].item()*100:.2f}%")

    return predicted_class, prediction_confidence

# Ejemplo de uso (descomenta para probar con una nueva imagen):
# predicted_class, confidence = predict_image(model, 'ruta/a/una/imagen.jpg', full_dataset.classes)